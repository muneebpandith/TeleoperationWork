{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cardinality=20\n",
    "output_cardinality=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0738c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.model_selection as sk\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81495b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytorch_lightning as pl\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940b1bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc51aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2683d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl.seed_everything(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac4eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.filenames = os.listdir(DATA_PATH)\n",
    "        self.filenames = [filename for filename in self.filenames if filename.endswith(\".csv\")]\n",
    "        self.len_filenames = len(self.filenames)\n",
    "        \n",
    "    def get_data(self):\n",
    "        self.data = []\n",
    "        for i in range(len(self.filenames)):\n",
    "            self.data.append(self.read_data(i))\n",
    "        return self.data\n",
    "    \n",
    "    def read_data(self,i):\n",
    "        return pd.read_csv(self.data_path+\"/\"+self.filenames[i])\n",
    "    \n",
    "\n",
    "    def process_data(self, scaler, input_cardinality=20, output_cardinality=10, cols=['ThetaXHG']):\n",
    "        self.datasamples = self.get_data()\n",
    "        X = []\n",
    "        y = []\n",
    "        X_scaled = []\n",
    "        y_scaled = []\n",
    "        for i, datasample in enumerate(self.datasamples):            \n",
    "            #for j in range(datasample[cols].shape[0]-output_cardinality):\n",
    "            #    print('Input' +str(j)+ ' to '+str(j+input_cardinality) + 'Output: '+str(j+input_cardinality)+ ' to '+str(j+input_cardinality+output_cardinality))\n",
    "            #Append to X (TO MAKE A LIST OF LISTS), [[0.019,1.02,...., upto input_cardinality]]\n",
    "            #Append to Y (TO MAKE A LIST OF LISTS), [[0.019,1.02,...., upto output_cardinality]]\n",
    "            #start of Y will be ahead of end of X by 1\n",
    "            \n",
    "            for j in range(datasample.shape[0]-output_cardinality-input_cardinality+1):\n",
    "                X.append(datasample[cols].iloc[j:j+input_cardinality].to_numpy())\n",
    "                y.append(datasample[cols].iloc[j+input_cardinality: j+input_cardinality+output_cardinality].to_numpy())\n",
    "                X_scaled.append(scaler.transform(datasample[cols].iloc[j:j+input_cardinality].to_numpy()))\n",
    "                y_scaled.append(scaler.transform(datasample[cols].iloc[j+input_cardinality: j+input_cardinality+output_cardinality].to_numpy()))\n",
    "        \n",
    "        #return self.datasamples, X, y\n",
    "        #print(np.array(X).shape,np.array(y).shape,np.array(X_scaled).shape, np.array(y_scaled).shape)\n",
    "        return self.datasamples, np.array(X), np.array(y), np.array(X_scaled), np.array(y_scaled)\n",
    "    \n",
    "    \n",
    "    def train_test_split(self, X, y, split={'train':0.8,'val':0.2, 'test':0.5}):\n",
    "        #print(X)\n",
    "        self.X_train, self.X_val_test, self.y_train, self.y_val_test = sk.train_test_split(X, y, test_size=split['val'] , random_state=43)\n",
    "        self.X_test, self.X_val, self.y_test, self.y_val = sk.train_test_split(self.X_val_test, self.y_val_test, test_size=split['test'] , random_state=43)\n",
    "        \n",
    "        return (self.X_train, self.y_train), (self.X_val, self.X_test), (self.X_test, self.y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getscaler(self,cols):\n",
    "        self.datasamples = self.get_data()       \n",
    "        for i, sample in enumerate(self.datasamples):\n",
    "            if i ==0:\n",
    "                features = pd.DataFrame(sample[cols])\n",
    "            else:\n",
    "                features = pd.DataFrame.append(features, sample[cols]) #sample[cols]\n",
    "   \n",
    "        #scaling\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        scaler = scaler.fit(features)\n",
    "        features_scaled = pd.DataFrame(scaler.transform(features), index = features.index, columns = cols)\n",
    "        return scaler\n",
    "    \n",
    "        \"\"\"        \n",
    "        #convert back to datasamples\n",
    "        #save to X\n",
    "        #save to X_scaled\n",
    "        \n",
    "        \n",
    "        #Split treain test and validation\n",
    "        \n",
    "        for i in range(features.shape[0]):\n",
    "            self.datasamples = []\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        return features, features_scaled\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5167df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329ba98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class THETADATASET(Dataset):\n",
    "    #convert to pytorch dataset\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, output = self.X[idx], self.y[idx]\n",
    "        return (torch.from_numpy(sequence.reshape(-1)), torch.from_numpy(output.reshape(-1)))\n",
    "        #return dict(sequence=torch.tensor(sequence.reshape(-1),dtype=torch.float64), label=torch.tensor(output.reshape(-1),dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4722168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class THETADATASETLOADER():\n",
    "    def __init__(self, data, batchsize, bs_val):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batchsize = batchsize\n",
    "        self.train_dataset = THETADATASET(self.data.X_train, self.data.y_train)\n",
    "        self.val_dataset = THETADATASET(self.data.X_val, self.data.y_val)\n",
    "        self.test_dataset = THETADATASET(self.data.X_test, self.data.y_test)\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size = self.batchsize, shuffle= False, num_workers=0)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size = bs_val, shuffle= False, num_workers=0)\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, batch_size = 1, shuffle= False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c884b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847ddc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders={}\n",
    "#dataloaders['train'], dataloaders['val'] = data_loaded.train_dataloader, data_loaded.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor f, o in tqdm(dataloaders['train']):\\n    #print(f[0].shape)\\n    break\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for f, o in tqdm(dataloaders['train']):\n",
    "    #print(f[0].shape)\n",
    "    break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(a,first['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(DATA_LOADED, model, criterion, optimizer, num_epochs=25):\n",
    "    #train_model(DATA_LOADED, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    start = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 0\n",
    "    dataloaders ={}\n",
    "    dataloaders['train'], dataloaders['val'] = DATA_LOADED.train_dataloader, DATA_LOADED.val_dataloader\n",
    "\n",
    "    #TR_ACCURACY=[]\n",
    "    TR_LOSS=[]\n",
    "    #VAL_ACCURACY=[]\n",
    "    VAL_LOSS=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        model.reset_hidden_states()\n",
    "        #model.reset_hidden_states()\n",
    "        #print(model.hidden)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            #running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            #if phase == 'train':\n",
    "            #    scheduler.step()\n",
    "\n",
    "            #epoch_loss = running_loss / DATA_LOADED.dataset_sizes[phase]\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            \n",
    "            #epoch_acc = running_corrects.double() / DATA.dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "\n",
    "            if phase == 'train':\n",
    "                #  print(\"Training\")\n",
    "                #  TR_ACCURACY.append(epoch_acc)\n",
    "                TR_LOSS.append(epoch_loss)\n",
    "            else:\n",
    "                print(\"Valuation\")\n",
    "                #VAL_ACCURACY.append(epoch_acc)\n",
    "                VAL_LOSS.append(epoch_loss)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return TR_LOSS, VAL_LOSS, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHALLEABLELSTMNET(nn.Module):\n",
    "    def __init__(self, batch_size, input_len, output_len, lstm_units = 4, num_layers=1):\n",
    "        super(LSTMNET, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        #input_size = no of features = 1\n",
    "        #hidden_size = no of lstm units in the layer\n",
    "        #num_layers = no of lstm layers\n",
    "        self.lstm_units = lstm_units\n",
    "        self.lstm1 = nn.LSTM(input_size= 1, hidden_size= lstm_units, num_layers=num_layers,batch_first=True, dropout=0.6)\n",
    "        \n",
    "        self.linear0 = nn.Linear(in_features= 20, out_features=10)\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features= lstm_units, out_features=10)\n",
    "        self.linear2 = nn.Linear(in_features= 10, out_features=10)\n",
    "        self.ll = nn.Linear(in_features= 10, out_features=output_len)\n",
    "        self.hidden = (torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).to(device).double(), torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).to(device).double())\n",
    "        #print(self.hidden[0].device)\n",
    "        #print(self.hidden.shape)\n",
    "        #self.hidden[0]= self.hidden[0].to(device)\n",
    "        #self.hidden[1] = self.hidden[1].to(device)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def reset_hidden_states(self):\n",
    "        self.hidden = (torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).double(), torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).double())\n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        #print(x)\n",
    "        #print(x.unsqueeze(-1).shape)\n",
    "        #print(self.hidden.shape)\n",
    "        #print(self.hidden)\n",
    "        #lstm_out, (h,c) = self.lstm1(x.unsqueeze(-1), self.hidden)\n",
    "        #self.hidden= (h.detach(),c.detach())\n",
    "        #c.detach_()\n",
    "        #h.detach_()\n",
    "        #self.hidden = (h.detach(), c.detach())\n",
    "        #print(ht.shape)\n",
    "        #ht=ht.to(device)\n",
    "        #ct=ct.to(device)\n",
    "        \n",
    "        #lstm_out = lstm_out[:,-1,:]\n",
    "        #print(ht.shape)\n",
    "        #either lstm_out goes to next or ht goes\n",
    "        #lstm_out= ht[-1]\n",
    "        #lin1_out = self.linear1(lstm_out)\n",
    "        #Add RELU\n",
    "        lin0_out = F.relu(self.linear0(x))\n",
    "        ll_out = self.ll(lin0_out)\n",
    "        #x = self.linear0(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.linear2(x)\n",
    "        #Add RELU\n",
    "        return ll_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNET(nn.Module):\n",
    "    def __init__(self, batch_size, input_len, output_len, lstm_units = 4, num_layers=1):\n",
    "        super(LSTMNET, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        #input_size = no of features = 1\n",
    "        #hidden_size = no of lstm units in the layer\n",
    "        #num_layers = no of lstm layers\n",
    "        self.lstm_units = lstm_units\n",
    "        self.lstm1 = nn.LSTM(input_size= 1, hidden_size= lstm_units, num_layers=num_layers,batch_first=True, dropout=0.6)\n",
    "        \n",
    "        self.linear0 = nn.Linear(in_features= 20, out_features=10)\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features= lstm_units, out_features=10)\n",
    "        self.linear2 = nn.Linear(in_features= 10, out_features=10)\n",
    "        self.ll = nn.Linear(in_features= 10, out_features=output_len)\n",
    "        self.hidden = (torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).double(), torch.zeros(1*self.num_layers, self.batch_size, self.lstm_units).double())\n",
    "        #print(self.hidden[0].device)\n",
    "        #print(self.hidden.shape)\n",
    "        #self.hidden[0]= self.hidden[0].to(device)\n",
    "        #self.hidden[1] = self.hidden[1].to(device)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def reset_hidden_states(self,bs):\n",
    "        self.hidden = (torch.zeros(1*self.num_layers, bs, self.lstm_units).double(), torch.zeros(1*self.num_layers, bs, self.lstm_units).double())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        #print(x)\n",
    "        #print(x.unsqueeze(-1).shape)\n",
    "        #print(self.hidden.shape)\n",
    "        #print(self.hidden)\n",
    "        lstm_out, (h,c) = self.lstm1(x.unsqueeze(-1), self.hidden)\n",
    "        self.hidden= (h.detach(),c.detach())\n",
    "        #c.detach_()\n",
    "        #h.detach_()\n",
    "        #self.hidden = (h.detach(), c.detach())\n",
    "        #print(ht.shape)\n",
    "        #ht=ht.to(device)\n",
    "        #ct=ct.to(device)\n",
    "        \n",
    "        lstm_out = lstm_out[:,-1,:]\n",
    "        #print(ht.shape)\n",
    "        #either lstm_out goes to next or ht goes\n",
    "        #lstm_out= h.detach()[-1]\n",
    "        lin1_out = self.linear1(lstm_out)\n",
    "        #Add RELU\n",
    "        #lin0_out = F.relu(self.linear0(x))\n",
    "        ll_out = self.ll(lin1_out)\n",
    "        #x = self.linear0(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.linear2(x)\n",
    "        #Add RELU\n",
    "        return ll_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500\n",
    "batch_size = 16\n",
    "bs_val = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./TRANSORMER_DATA\"\n",
    "data = DATA(DATA_PATH)\n",
    "cols=['ThetaXHG']\n",
    "scaler = data.getscaler(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, X, y, X_scaled, y_scaled = data.process_data(scaler, input_cardinality=input_cardinality, output_cardinality=output_cardinality, cols=['ThetaXHG'])\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = data.train_test_split(X_scaled,y_scaled,  split={'train':0.8,'val':0.2, 'test':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 2, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "net = LSTMNET(batch_size=batch_size,input_len=input_cardinality,output_len=output_cardinality)\n",
    "net = net.to(device)\n",
    "net = net.double()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first['sequence'].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = THETADATASETLOADER(data, batchsize=batch_size, bs_val = bs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size={}\n",
    "dataset_size['train'] =X_train.shape[0]\n",
    "dataset_size['val'] =X_val.shape[0]\n",
    "dataset_size['test'] =X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_LOSS = []\n",
    "VAL_LOSS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "722/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(epochs):\\n    net.reset_hidden_states(bs=batch_size)\\n    it = iter(data_loaded.train_dataloader)\\n    it_val = iter(data_loaded.train_dataloader)\\n    print('Epoch'+str(i))\\n    c = 0\\n    tr_loss = 0.0\\n    val_loss = 0.0\\n    \\n    while c < int(X_train.shape[0]/batch_size): \\n        with torch.set_grad_enabled(True):\\n            #print(c)\\n            c = c+1\\n            item = next(it)\\n            outputs = net(item[0])\\n            tr_loss = tr_loss + criterion(outputs, item[1])\\n    \\n    TR_LOSS.append(tr_loss)\\n    print(tr_loss)\\n    optimizer.zero_grad()\\n    tr_loss.backward()\\n    optimizer.step()\\n    \\n    net.reset_hidden_states(bs=bs_val)\\n    #print(net.hidden[0].shape)\\n    while c < int(X_val.shape[0]/bs_val):\\n        net.eval()\\n        with torch.set_grad_enabled(False):\\n            #print(c)\\n            c = c+1\\n            item = next(it_val)\\n            outputs = net(item[0])\\n            val_loss = val_loss + criterion(outputs, item[1])\\n    VAL_LOSS.append(val_loss)\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do separately Val loss and train loss\n",
    "\"\"\"for i in range(epochs):\n",
    "    net.reset_hidden_states(bs=batch_size)\n",
    "    it = iter(data_loaded.train_dataloader)\n",
    "    it_val = iter(data_loaded.train_dataloader)\n",
    "    print('Epoch'+str(i))\n",
    "    c = 0\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    while c < int(X_train.shape[0]/batch_size): \n",
    "        with torch.set_grad_enabled(True):\n",
    "            #print(c)\n",
    "            c = c+1\n",
    "            item = next(it)\n",
    "            outputs = net(item[0])\n",
    "            tr_loss = tr_loss + criterion(outputs, item[1])\n",
    "    \n",
    "    TR_LOSS.append(tr_loss)\n",
    "    print(tr_loss)\n",
    "    optimizer.zero_grad()\n",
    "    tr_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    net.reset_hidden_states(bs=bs_val)\n",
    "    #print(net.hidden[0].shape)\n",
    "    while c < int(X_val.shape[0]/bs_val):\n",
    "        net.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            #print(c)\n",
    "            c = c+1\n",
    "            item = next(it_val)\n",
    "            outputs = net(item[0])\n",
    "            val_loss = val_loss + criterion(outputs, item[1])\n",
    "    VAL_LOSS.append(val_loss)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.7143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch0 >> Training Loss: tensor(30.7143, dtype=torch.float64, grad_fn=<AddBackward0>) Validation Loss: tensor(0.6878, dtype=torch.float64) <<\n",
      "tensor(6.2978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch1 >> Training Loss: tensor(6.2978, dtype=torch.float64, grad_fn=<AddBackward0>) Validation Loss: tensor(0.9693, dtype=torch.float64) <<\n",
      "tensor(9.1861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch2 >> Training Loss: tensor(9.1861, dtype=torch.float64, grad_fn=<AddBackward0>) Validation Loss: tensor(0.9357, dtype=torch.float64) <<\n",
      "tensor(8.7813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch3 >> Training Loss: tensor(8.7813, dtype=torch.float64, grad_fn=<AddBackward0>) Validation Loss: tensor(0.7372, dtype=torch.float64) <<\n",
      "tensor(6.7335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch4 >> Training Loss: tensor(6.7335, dtype=torch.float64, grad_fn=<AddBackward0>) Validation Loss: tensor(0.6003, dtype=torch.float64) <<\n"
     ]
    }
   ],
   "source": [
    "#Do separately Val loss and train loss\n",
    "TR_LOSS = []\n",
    "VAL_LOSS = []\n",
    "for i in range(epochs):\n",
    "    net.train()\n",
    "    net.reset_hidden_states(bs=batch_size)\n",
    "    #print(net.hidden[0].shape)\n",
    "    it = iter(data_loaded.train_dataloader)\n",
    "    it_val = iter(data_loaded.train_dataloader)\n",
    "    c = 0\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    while c < int(X_train.shape[0]/batch_size): \n",
    "        with torch.set_grad_enabled(True):\n",
    "            #print(c)\n",
    "            c = c+1\n",
    "            item = next(it)\n",
    "            inputs = item[0].to(device)\n",
    "            labels = item[1].to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            tr_loss = tr_loss + criterion(outputs, labels)\n",
    "    \n",
    "    TR_LOSS.append(tr_loss)\n",
    "    print(tr_loss)\n",
    "    optimizer.zero_grad()\n",
    "    tr_loss.backward()\n",
    "    optimizer.step()\n",
    "    c = 0\n",
    "    \n",
    "    #net.reset_hidden_states(bs=bs_val)\n",
    "    #print(net.hidden[0].shape)\n",
    "    #print(net.hidden[0].shape)\n",
    "    while c < int(X_val.shape[0]/bs_val):\n",
    "        net.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            #print(c)\n",
    "            c = c+1\n",
    "            item = next(it_val)\n",
    "            inputs = item[0].to(device)\n",
    "            labels = item[1].to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            val_loss = val_loss + criterion(outputs, labels)\n",
    "            #print(val_loss)\n",
    "    VAL_LOSS.append(val_loss)\n",
    "    print('Epoch'+str(i)+ ' >> Training Loss: '+str(tr_loss)+ ' Validation Loss: '+str(val_loss)+ ' <<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(TR_LOSS)\n",
    "plt.plot(VAL_LOSS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.7903, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "accumulated_test_loss = 0.0\n",
    "net.reset_hidden_states(bs=1)\n",
    "it_test = iter(data_loaded.test_dataloader)\n",
    "c=0\n",
    "while c < int(X_test.shape[0]/1):\n",
    "    #net.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        #print(c)\n",
    "        c = c+1\n",
    "        item = next(it_test)\n",
    "        outputs = net(item[0])\n",
    "        accumulated_test_loss = accumulated_test_loss + criterion(outputs, item[1])        \n",
    "print(accumulated_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('RESULTS_LOSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss_array = []\n",
    "for z in TR_LOSS:\n",
    "    tr_loss_array.append(z.tolist())\n",
    "training_loss = pd.DataFrame(tr_loss_array, columns=['TR_LOSS'])\n",
    "training_loss.to_csv('./RESULTS_LOSS/TR_LOSS_'+str(output_cardinality)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_array = []\n",
    "for z in VAL_LOSS:\n",
    "    val_loss_array.append(z.tolist())\n",
    "val_loss = pd.DataFrame(val_loss_array, columns=['VAL_LOSS'])\n",
    "val_loss.to_csv('./RESULTS_LOSS/VAL_LOSS_'+str(output_cardinality)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_array = [accumulated_test_loss]\n",
    "\n",
    "test2_loss = pd.DataFrame(test_loss_array, columns=['TEST_LOSS'])\n",
    "test2_loss.to_csv('./RESULTS_LOSS/TEST_LOSS_'+str(output_cardinality)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
